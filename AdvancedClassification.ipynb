{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = \"D:/4th year 2nd semester/NLP/Assignment-1 Text Classification/training\"\n",
    "test_data_path=\"D:/4th year 2nd semester/NLP/Assignment-1 Text Classification/test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Download NLTK resources\n",
    "# nltk.download('punkt')\n",
    "\n",
    "# Initialize Porter Stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Tokenization and normalization\n",
    "def tokenize_normalize(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    normalized_tokens = [stemmer.stem(token) for token in tokens]\n",
    "    return normalized_tokens\n",
    "\n",
    "# Extract vocabulary set\n",
    "def extract_vocabulary(documents):\n",
    "    vectorizer = CountVectorizer(tokenizer=tokenize_normalize)\n",
    "    vectorizer.fit_transform(documents)\n",
    "    return vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "def preprocess_data(data_path):\n",
    "    documents = []\n",
    "    classes = []\n",
    "    \n",
    "    for label in os.listdir(data_path):\n",
    "        label_path = os.path.join(data_path, label)\n",
    "        if os.path.isdir(label_path):\n",
    "            for file_name in os.listdir(label_path):\n",
    "                file_path = os.path.join(label_path, file_name)\n",
    "                with open(file_path, 'r', encoding='utf-8', errors='replace') as file:\n",
    "                    content = file.read()\n",
    "                    documents.append(content)\n",
    "                    classes.append(label) \n",
    "    \n",
    "    vocabulary = extract_vocabulary(documents)\n",
    "    \n",
    "    return documents, classes, vocabulary\n",
    "\n",
    "# Load and preprocess data\n",
    "documents, classes, vocabulary = preprocess_data(train_data_path)\n",
    "test_documents, test_classes, test_vocabulary = preprocess_data(test_data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11413\n",
      "4024\n"
     ]
    }
   ],
   "source": [
    "print(len (documents))\n",
    "print(len (test_documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TF-IDF Feature Encoding\n",
    "def tfidf_feature_encoding(documents):\n",
    "    vectorizer = TfidfVectorizer(tokenizer=tokenize_normalize, vocabulary=vocabulary)\n",
    "    X = vectorizer.fit_transform(documents)\n",
    "    return X\n",
    "\n",
    "# Splitting data into train and test sets\n",
    "X_tfidf = tfidf_feature_encoding(documents)\n",
    "y = classes\n",
    "X_train_tfidf, X_test_tfidf, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "test_x_tfidf = tfidf_feature_encoding(test_documents)\n",
    "test_y = test_classes \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word Embedding \n",
    "\n",
    "word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "\n",
    "# Tokenize documents\n",
    "tokenized_documents = [tokenize_normalize(doc) for doc in documents]\n",
    "test_tokenized_documents = [tokenize_normalize(doc) for doc in test_documents]\n",
    "\n",
    "\n",
    "# Training Word2Vec model\n",
    "word2vec_model = Word2Vec(sentences=tokenized_documents, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "def generate_doc_embeddings(documents, word2vec_model):\n",
    "    embeddings = []\n",
    "    for doc in documents:\n",
    "        doc_embedding = np.mean([word2vec_model.wv[word] for word in doc if word in word2vec_model.wv], axis=0)\n",
    "        embeddings.append(doc_embedding)\n",
    "    return np.array(embeddings)\n",
    "\n",
    "# Generate document embeddings\n",
    "x_word2vec = generate_doc_embeddings(tokenized_documents, word2vec_model)\n",
    "\n",
    "# Splitting data into train and test sets\n",
    "x_train_word2vec, x_test_word2vec, _, _ = train_test_split(x_word2vec, y, test_size=0.2, random_state=42)\n",
    "\n",
    "test_x_word2vec = generate_doc_embeddings(test_tokenized_documents, word2vec_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "# Train FastText model\n",
    "fasttext_model = FastText(sentences=tokenized_documents, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Function to generate document embeddings using FastText\n",
    "def generate_doc_embeddings_fasttext(documents, fasttext_model):\n",
    "    embeddings = []\n",
    "    for doc in documents:\n",
    "        doc_embedding = np.mean([fasttext_model.wv[word] for word in doc if word in fasttext_model.wv], axis=0)\n",
    "        embeddings.append(doc_embedding)\n",
    "    return np.array(embeddings)\n",
    "\n",
    "# Generate document embeddings using FastText\n",
    "X_fasttext = generate_doc_embeddings_fasttext(tokenized_documents, fasttext_model)\n",
    "\n",
    "# Splitting data into train and test sets\n",
    "X_train_fasttext, X_test_fasttext, _, _ = train_test_split(X_fasttext, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Generate document embeddings for test data using FastText\n",
    "test_X_fasttext = generate_doc_embeddings_fasttext(test_tokenized_documents, fasttext_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def svm(X_train, y_train, X_test, y_test):\n",
    "    # Training SVM classifier\n",
    "    svm_classifier = SVC(kernel='linear')\n",
    "    svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    y_pred_svm = svm_classifier.predict(X_test)\n",
    "\n",
    "    # Evaluating SVM classifier\n",
    "    svm_report = classification_report(y_test, y_pred_svm, output_dict=True)\n",
    "    macro_avg_f1_score = svm_report['macro avg']['f1-score']\n",
    "    return macro_avg_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier with TF-IDF features (train test split): 0.2864851217060963\n",
      "SVM Classifier with TF-IDF features (test file): 0.3088820036862362\n"
     ]
    }
   ],
   "source": [
    "# Evaluating SVM classifier with tfidf\n",
    "score = svm(X_train_tfidf, y_train, X_test_tfidf, y_test)\n",
    "print(\"SVM Classifier with TF-IDF features (train test split):\", score)\n",
    "\n",
    "test_score = svm(X_tfidf, y, test_x_tfidf, test_y)\n",
    "print(\"SVM Classifier with TF-IDF features (test file):\", test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier with Word2Vec embeddings (train-test split): 0.22449812843364533\n",
      "SVM Classifier with Word2Vec embeddings (test file): 0.190862263844645\n",
      "SVM Classifier with FastText embeddings (train-test split): 0.20494788202662198\n",
      "SVM Classifier with FastText embeddings (test file): 0.17210019967246384\n"
     ]
    }
   ],
   "source": [
    "# Evaluating SVM classifier with Word2Vec embeddings\n",
    "word2vec_train_score = svm(x_train_word2vec, y_train, x_test_word2vec, y_test)\n",
    "print(\"SVM Classifier with Word2Vec embeddings (train-test split):\", word2vec_train_score)\n",
    "word2vec_test_score = svm(x_word2vec, y, test_x_word2vec, test_y)\n",
    "print(\"SVM Classifier with Word2Vec embeddings (test file):\", word2vec_test_score)\n",
    "\n",
    "\n",
    "# Evaluating SVM classifier with FastText embeddings\n",
    "fasttext_train_score = svm(X_train_fasttext, y_train, X_test_fasttext, y_test)\n",
    "print(\"SVM Classifier with FastText embeddings (train-test split):\", fasttext_train_score)\n",
    "fasttext_test_score = svm(X_fasttext, y, test_X_fasttext, test_y)\n",
    "print(\"SVM Classifier with FastText embeddings (test file):\", fasttext_test_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def randomForest(X_train,y_train, X_test, y_test):\n",
    "    # Initialize Random Forest Classifier\n",
    "    rf_classifier = RandomForestClassifier()\n",
    "\n",
    "    # Train the model\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    rf_predictions = rf_classifier.predict(X_test)\n",
    "\n",
    "    # Evaluation\n",
    "    rf_report = classification_report(y_test, rf_predictions, output_dict=True)\n",
    "    rf_macro_f1 = rf_report['macro avg']['f1-score']\n",
    "    # print(\"Random Forest Macro F1 Score:\", rf_macro_f1)\n",
    "    return rf_macro_f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF score with tfidf (test train split) 0.15471053802528603\n",
      "RF score with tfidf (test) 0.16923094708235253\n"
     ]
    }
   ],
   "source": [
    "# tfidf\n",
    "rf_score=randomForest(X_train_tfidf, y_train, X_test_tfidf, y_test)\n",
    "print('RF score with tfidf (test train split)', rf_score)\n",
    "test_rf_score=randomForest(X_tfidf, y, test_x_tfidf, test_y)\n",
    "print('RF score with tfidf (test)', test_rf_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF score with word2vec (test train split) 0.13994509605607774\n",
      "RF score with word2vec (test) 0.15076227715864104\n",
      "RF score with fasttext (test train split) 0.1096545262357273\n",
      "RF score with fasttext (test) 0.1332533705474679\n"
     ]
    }
   ],
   "source": [
    "# word2vec\n",
    "rf_score_word2vec=randomForest(x_train_word2vec, y_train, x_test_word2vec, y_test)\n",
    "print('RF score with word2vec (test train split)', rf_score_word2vec)\n",
    "test_rf_score_word2vec=randomForest(x_word2vec, y, test_x_word2vec, test_y)\n",
    "print('RF score with word2vec (test)', test_rf_score_word2vec)\n",
    "\n",
    "# fasttext\n",
    "rf_score_fasttext=randomForest(X_train_fasttext, y_train, X_test_fasttext, y_test)\n",
    "print('RF score with fasttext (test train split)', rf_score_fasttext)\n",
    "test_rf_score_fasttext=randomForest(X_fasttext, y, test_X_fasttext, test_y)\n",
    "print('RF score with fasttext (test)', test_rf_score_fasttext)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def knn(X_train, y_train, X_test, y_test):\n",
    "    # Initialize KNN Classifier\n",
    "    knn_classifier = KNeighborsClassifier()\n",
    "\n",
    "    # Train the model\n",
    "    knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    knn_predictions = knn_classifier.predict(X_test)\n",
    "\n",
    "    # Evaluation\n",
    "    knn_report = classification_report(y_test, knn_predictions, output_dict=True)\n",
    "    knn_macro_f1 = knn_report['macro avg']['f1-score']\n",
    "    #print(\"KNN Macro F1 Score:\", knn_macro_f1)\n",
    "    return knn_macro_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN score with tfidf (test train split) 0.24910580950546563\n",
      "KNN score with tfidf (test) 0.2974893559065393\n"
     ]
    }
   ],
   "source": [
    "# tfidf\n",
    "knn_score=knn(X_train_tfidf, y_train, X_test_tfidf, y_test)\n",
    "print('KNN score with tfidf (test train split)', knn_score)\n",
    "test_knn_score=knn(X_tfidf, y, test_x_tfidf, test_y)\n",
    "print('KNN score with tfidf (test)', test_knn_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN score with word2vec (test train split) 0.16470255508656254\n",
      "KNN score with word2vec (test) 0.1416713169278412\n",
      "KNN score with fasttext (test train split) 0.12837508831502473\n",
      "KNN score with fasttext (test) 0.11888476470699161\n"
     ]
    }
   ],
   "source": [
    "# word2vec\n",
    "knn_score_word2vec=knn(x_train_word2vec, y_train, x_test_word2vec, y_test)\n",
    "print('KNN score with word2vec (test train split)', knn_score_word2vec)\n",
    "test_knn_score_word2vec=randomForest(x_word2vec, y, test_x_word2vec, test_y)\n",
    "print('KNN score with word2vec (test)', test_knn_score_word2vec)\n",
    "\n",
    "# fasttext\n",
    "knn_score_fasttext=knn(X_train_fasttext, y_train, X_test_fasttext, y_test)\n",
    "print('KNN score with fasttext (test train split)', knn_score_fasttext)\n",
    "test_knn_score_fasttext=randomForest(X_fasttext, y, test_X_fasttext, test_y)\n",
    "print('KNN score with fasttext (test)', test_knn_score_fasttext)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 33ms/step - accuracy: 0.4544 - loss: 3.4734 - val_accuracy: 0.0066 - val_loss: 8.8413\n",
      "Epoch 2/10\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.6765 - loss: 1.4537 - val_accuracy: 0.0197 - val_loss: 10.7349\n",
      "Epoch 3/10\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - accuracy: 0.7514 - loss: 1.0090 - val_accuracy: 0.0219 - val_loss: 11.9475\n",
      "Epoch 4/10\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.7892 - loss: 0.7659 - val_accuracy: 0.0206 - val_loss: 12.7933\n",
      "Epoch 5/10\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 32ms/step - accuracy: 0.8076 - loss: 0.6157 - val_accuracy: 0.0210 - val_loss: 13.3172\n",
      "Epoch 6/10\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - accuracy: 0.8101 - loss: 0.5309 - val_accuracy: 0.0219 - val_loss: 13.8087\n",
      "Epoch 7/10\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.8243 - loss: 0.4588 - val_accuracy: 0.0193 - val_loss: 14.1913\n",
      "Epoch 8/10\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - accuracy: 0.8141 - loss: 0.4259 - val_accuracy: 0.0219 - val_loss: 14.5438\n",
      "Epoch 9/10\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - accuracy: 0.8245 - loss: 0.3821 - val_accuracy: 0.0193 - val_loss: 14.7624\n",
      "Epoch 10/10\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - accuracy: 0.8237 - loss: 0.3654 - val_accuracy: 0.0188 - val_loss: 14.9608\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step\n",
      "Macro Avg F1 Score: 0.28224247529525326\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode string labels to integer labels\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Define the RNN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(X_tfidf.shape[1],)),\n",
    "    tf.keras.layers.Reshape((1, X_tfidf.shape[1])),\n",
    "    tf.keras.layers.SimpleRNN(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(91, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "# X_tfidf = X_tfidf.toarray()  # Convert to NumPy array if not already\n",
    "# y = np.array(y)  # Convert to NumPy array if not already\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_tfidf, y_encoded, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Convert sparse matrix to dense array\n",
    "test_x_tfidf_dense = test_x_tfidf.toarray()\n",
    "\n",
    "# Predict on test set\n",
    "predictions = np.argmax(model.predict(test_x_tfidf_dense), axis=-1)\n",
    "\n",
    "# Convert string labels to integer labels for test_y\n",
    "test_y_encoded = label_encoder.transform(test_y)\n",
    "\n",
    "# Compute macro avg f1 score\n",
    "macro_f1 = f1_score(test_y_encoded, predictions, average='macro')\n",
    "print(\"Macro Avg F1 Score:\", macro_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 96ms/step - accuracy: 0.3780 - loss: 3.7801 - val_accuracy: 0.0066 - val_loss: 8.4407\n",
      "Epoch 2/10\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 83ms/step - accuracy: 0.6448 - loss: 1.6078 - val_accuracy: 0.0210 - val_loss: 11.0633\n",
      "Epoch 3/10\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 82ms/step - accuracy: 0.7286 - loss: 1.1006 - val_accuracy: 0.0228 - val_loss: 12.9492\n",
      "Epoch 4/10\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 83ms/step - accuracy: 0.7785 - loss: 0.8089 - val_accuracy: 0.0223 - val_loss: 14.2877\n",
      "Epoch 5/10\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 83ms/step - accuracy: 0.8009 - loss: 0.6569 - val_accuracy: 0.0228 - val_loss: 15.3792\n",
      "Epoch 6/10\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 87ms/step - accuracy: 0.8052 - loss: 0.5455 - val_accuracy: 0.0223 - val_loss: 16.1051\n",
      "Epoch 7/10\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 87ms/step - accuracy: 0.8145 - loss: 0.4638 - val_accuracy: 0.0201 - val_loss: 16.7045\n",
      "Epoch 8/10\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 90ms/step - accuracy: 0.8159 - loss: 0.4284 - val_accuracy: 0.0223 - val_loss: 17.1433\n",
      "Epoch 9/10\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 87ms/step - accuracy: 0.8145 - loss: 0.4057 - val_accuracy: 0.0219 - val_loss: 17.6290\n",
      "Epoch 10/10\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 87ms/step - accuracy: 0.8240 - loss: 0.3734 - val_accuracy: 0.0193 - val_loss: 17.9094\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step\n",
      "Macro Avg F1 Score: 0.2856559076502796\n"
     ]
    }
   ],
   "source": [
    "# Define the RNN model with LSTM\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(X_tfidf.shape[1],)),\n",
    "    tf.keras.layers.Reshape((1, X_tfidf.shape[1])),\n",
    "    tf.keras.layers.LSTM(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(91, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_tfidf, y_encoded, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Convert string labels to integer labels for test_y\n",
    "test_y_encoded = label_encoder.transform(test_y)\n",
    "\n",
    "# Predict on test set\n",
    "predictions = np.argmax(model.predict(test_x_tfidf_dense), axis=-1)\n",
    "\n",
    "# Compute macro avg f1 score\n",
    "macro_f1 = f1_score(test_y_encoded, predictions, average='macro')\n",
    "print(\"Macro Avg F1 Score:\", macro_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 169ms/step - accuracy: 0.3866 - loss: 3.5482 - val_accuracy: 0.0127 - val_loss: 9.0764\n",
      "Epoch 2/10\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 166ms/step - accuracy: 0.6765 - loss: 1.4124 - val_accuracy: 0.0223 - val_loss: 12.0484\n",
      "Epoch 3/10\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 170ms/step - accuracy: 0.7670 - loss: 0.8851 - val_accuracy: 0.0232 - val_loss: 14.4091\n",
      "Epoch 4/10\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 167ms/step - accuracy: 0.7972 - loss: 0.6593 - val_accuracy: 0.0223 - val_loss: 15.5666\n",
      "Epoch 5/10\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 169ms/step - accuracy: 0.8083 - loss: 0.5378 - val_accuracy: 0.0223 - val_loss: 16.6488\n",
      "Epoch 6/10\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 167ms/step - accuracy: 0.8168 - loss: 0.4494 - val_accuracy: 0.0206 - val_loss: 17.0948\n",
      "Epoch 7/10\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 163ms/step - accuracy: 0.8203 - loss: 0.3929 - val_accuracy: 0.0210 - val_loss: 17.6775\n",
      "Epoch 8/10\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 166ms/step - accuracy: 0.8215 - loss: 0.3711 - val_accuracy: 0.0223 - val_loss: 17.8533\n",
      "Epoch 9/10\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 168ms/step - accuracy: 0.8154 - loss: 0.3685 - val_accuracy: 0.0223 - val_loss: 18.1649\n",
      "Epoch 10/10\n",
      "\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 174ms/step - accuracy: 0.8287 - loss: 0.3322 - val_accuracy: 0.0223 - val_loss: 18.3775\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step\n",
      "Macro Avg F1 Score: 0.3118913535772544\n"
     ]
    }
   ],
   "source": [
    "# Define the RNN model with LSTM\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(X_tfidf.shape[1],)),\n",
    "    tf.keras.layers.Reshape((1, X_tfidf.shape[1])),\n",
    "    tf.keras.layers.LSTM(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(91, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_tfidf, y_encoded, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Convert string labels to integer labels for test_y\n",
    "test_y_encoded = label_encoder.transform(test_y)\n",
    "\n",
    "# Predict on test set\n",
    "predictions = np.argmax(model.predict(test_x_tfidf_dense), axis=-1)\n",
    "\n",
    "# Compute macro avg f1 score\n",
    "macro_f1 = f1_score(test_y_encoded, predictions, average='macro')\n",
    "print(\"Macro Avg F1 Score:\", macro_f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
